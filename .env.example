# ============================================
# QANexus Environment Configuration
# ============================================
# Copy this file to .env and fill in your values
# cp .env.example .env
# ============================================

# ============================================
# Application
# ============================================
NODE_ENV=development
PORT=3000

# ============================================
# Database (Neon - Free Tier)
# ============================================
# Get your connection string from: https://neon.tech
# Format: postgres://user:password@host/database?sslmode=require
DATABASE_URL=postgres://user:password@ep-xxx.us-east-1.aws.neon.tech/qanexus?sslmode=require

# Individual DB settings (for local docker-compose)
DB_HOST=localhost
DB_PORT=5432
DB_USER=qanexus
DB_PASSWORD=qanexus_dev_password
DB_NAME=qanexus

# ============================================
# Authentication
# ============================================
# Generate a secure secret: openssl rand -base64 32
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_EXPIRATION=1d

# ============================================
# AI Provider Configuration
# ============================================
# Default provider (tenant config in DB overrides this)
# Options: openai | gemini | anthropic | foundry_local
AI_PROVIDER=foundry_local

# ============================================
# Option 1: Cloud APIs (User-supplied API keys)
# ============================================
# API keys are typically stored per-tenant in the database.
# These env vars are optional system-wide defaults.

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Google Gemini (https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=...
GEMINI_MODEL=gemini-1.5-flash
GEMINI_EMBEDDING_MODEL=text-embedding-004

# Anthropic Claude (https://console.anthropic.com/settings/keys)
# Note: Anthropic doesn't have embeddings - uses OpenAI or Foundry Local for embeddings
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# ============================================
# Option 2: Foundry Local (On-Device AI)
# ============================================
# 100% local inference - no data leaves your machine
# Install: https://github.com/microsoft/Foundry-Local
# Windows: winget install Microsoft.FoundryLocal
# macOS: brew install microsoft/foundrylocal/foundrylocal
FOUNDRY_LOCAL_ENDPOINT=http://127.0.0.1:55588/v1
FOUNDRY_LOCAL_MODEL=phi-3.5-mini
FOUNDRY_LOCAL_EMBEDDING_MODEL=nomic-embed-text

# ============================================
# Vector Store (for RAG)
# ============================================
# Options: pgvector | memory
VECTOR_STORE=pgvector

# ============================================
# Redis (Optional - for caching/rate limiting)
# ============================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# ============================================
# CORS Configuration
# ============================================
# Comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# ============================================
# Rate Limiting
# ============================================
RATE_LIMIT_TTL=60
RATE_LIMIT_MAX=100

# ============================================
# Logging
# ============================================
# Options: debug | info | warn | error
LOG_LEVEL=debug
