# ============================================
# QANexus Environment Configuration
# ============================================
# Copy this file to .env and fill in your values
# cp .env.example .env
# ============================================

# ============================================
# Application
# ============================================
NODE_ENV=development
PORT=3000

# ============================================
# Database (Neon - Free Tier)
# ============================================
# Get your connection string from: https://neon.tech
# Format: postgres://user:password@host/database?sslmode=require
DATABASE_URL=postgres://user:password@ep-xxx.us-east-1.aws.neon.tech/qanexus?sslmode=require

# Individual DB settings (for local docker-compose)
DB_HOST=localhost
DB_PORT=5432
DB_USER=qanexus
DB_PASSWORD=qanexus_dev_password
DB_NAME=qanexus

# ============================================
# Authentication
# ============================================
# Generate a secure secret: openssl rand -base64 32
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_EXPIRATION=1d

# ============================================
# AI Provider Configuration
# ============================================
# Options: mock | azure | local
AI_PROVIDER=mock

# ============================================
# Azure OpenAI (when AI_PROVIDER=azure)
# ============================================
# Apply for access at: https://aka.ms/oai/access
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT_GPT4=gpt-4-deployment
AZURE_OPENAI_DEPLOYMENT_GPT4_MINI=gpt-4o-mini-deployment
AZURE_OPENAI_DEPLOYMENT_EMBEDDING=text-embedding-ada-002

# ============================================
# Local AI - Ollama (when AI_PROVIDER=local)
# ============================================
# Install Ollama: https://ollama.ai
# Run: ollama pull llama2 && ollama pull nomic-embed-text
LOCAL_LLM_BASE_URL=http://localhost:11434/v1
LOCAL_EMBEDDING_BASE_URL=http://localhost:11434/v1
LOCAL_LLM_MODEL=llama2
LOCAL_EMBEDDING_MODEL=nomic-embed-text

# ============================================
# Vector Store (for RAG)
# ============================================
# Options: pgvector | memory
VECTOR_STORE=pgvector

# ============================================
# Redis (Optional - for caching/rate limiting)
# ============================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# ============================================
# CORS Configuration
# ============================================
# Comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# ============================================
# Rate Limiting
# ============================================
RATE_LIMIT_TTL=60
RATE_LIMIT_MAX=100

# ============================================
# Logging
# ============================================
# Options: debug | info | warn | error
LOG_LEVEL=debug
