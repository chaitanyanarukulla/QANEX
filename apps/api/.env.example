# ============================================
# QANexus API - Environment Configuration
# ============================================
# Copy to .env: cp .env.example .env
# ============================================

# ============================================
# Server
# ============================================
NODE_ENV=development
PORT=3000

# ============================================
# Database
# ============================================
# Option 1: Neon (Production/Free Tier)
DATABASE_URL=postgres://user:password@ep-xxx.us-east-1.aws.neon.tech/qanexus?sslmode=require

# Option 2: Local Docker (Development)
DB_HOST=localhost
DB_PORT=5432
DB_USER=qanexus
DB_PASSWORD=qanexus_dev_password
DB_NAME=qanexus
DB_SSL=false

# ============================================
# Authentication
# ============================================
JWT_SECRET=change-this-to-a-secure-random-string
JWT_EXPIRATION=1d

# ============================================
# AI Provider Configuration
# ============================================
# Default provider (tenant config in DB overrides this)
# Options: openai | gemini | anthropic | foundry_local
AI_PROVIDER=foundry_local

# ============================================
# Option 1: Cloud APIs (User-supplied API keys)
# ============================================
# API keys are typically stored per-tenant in the database.
# These env vars are optional system-wide defaults.

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Google Gemini (https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=...
GEMINI_MODEL=gemini-1.5-flash
GEMINI_EMBEDDING_MODEL=text-embedding-004

# Anthropic Claude (https://console.anthropic.com/settings/keys)
# Note: Anthropic doesn't have embeddings - uses OpenAI or Foundry Local for embeddings
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# ============================================
# Option 2: Foundry Local (On-Device AI)
# ============================================
# 100% local inference - no data leaves your machine
# Install: https://github.com/microsoft/Foundry-Local
# Windows: winget install Microsoft.FoundryLocal
# macOS: brew install microsoft/foundrylocal/foundrylocal
FOUNDRY_LOCAL_ENDPOINT=http://127.0.0.1:55588/v1
FOUNDRY_LOCAL_MODEL=phi-3.5-mini
FOUNDRY_LOCAL_EMBEDDING_MODEL=nomic-embed-text

# ============================================
# Vector Store (for RAG)
# ============================================
# Options: pgvector | memory
VECTOR_STORE=pgvector

# ============================================
# Redis (Optional - for caching/rate limiting)
# ============================================
REDIS_URL=redis://localhost:6379

# ============================================
# Security
# ============================================
CORS_ORIGINS=http://localhost:3001,http://localhost:3000
RATE_LIMIT_TTL=60
RATE_LIMIT_MAX=100

# ============================================
# Logging
# ============================================
# Options: debug | info | warn | error
LOG_LEVEL=debug
