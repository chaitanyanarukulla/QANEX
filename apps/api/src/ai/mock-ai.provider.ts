import { Injectable, Logger } from '@nestjs/common';
import { AiProvider } from './ai.interface';

@Injectable()
export class MockAiProvider implements AiProvider {
  private readonly logger = new Logger(MockAiProvider.name);

  async analyzeRequirement(
    content: string,
    tenantId: string,
    _apiKey?: string,
  ): Promise<{
    score: number;
    clarity: number;
    completeness: number;
    testability: number;
    consistency: number;
    feedback: string[];
  }> {
    this.logger.log(`Mock AI analyzing requirement for ${tenantId}`);
    const score = content.length > 50 ? 85 : 40;
    return {
      score,
      clarity: 80,
      completeness: score,
      testability: 90,
      consistency: 85,
      feedback:
        score < 50
          ? ['Description too short', 'Lack of acceptance criteria']
          : ['Good quality'],
    };
  }

  async triageBug(
    bugValues: { title: string; description: string },
    tenantId: string,
    _apiKey?: string,
  ) {
    this.logger.log(`Mock AI triaging bug for ${tenantId}`);
    const _isCritical = bugValues.title.toLowerCase().includes('crash');
    return {
      suggestedSeverity: bugValues.title.toLowerCase().includes('crash')
        ? 'CRITICAL'
        : 'MEDIUM',
      suggestedPriority: bugValues.title.toLowerCase().includes('crash')
        ? 'P0'
        : 'P2',
      duplicateCandidates: [],
      rootCauseHypothesis:
        'Based on the description, this looks like a potential null pointer exception in the render loop.',
    };
  }

  async generateTestCode(
    testCase: { title: string; steps: any[] },
    _framework: string,
    _tenantId: string,
    _apiKey?: string,
  ): Promise<string> {
    return `
import { test, expect } from '@playwright/test';

test('${testCase.title}', async ({ page }) => {
    // Generated by QANexus AI (MOCK)
    // Steps:
    ${testCase.steps.map((s) => `// - ${s.step} (Expect: ${s.expected})`).join('\n    ')}

    await page.goto('/');
    // TODO: Implement specific selectors
});
`;
  }

  async callChat(
    _prompt: string,
    _tenantId: string,
    _apiKey?: string,
  ): Promise<string> {
    return 'This is a mock AI response. Real AI interaction requires configuration.';
  }

  async explainRcs(releaseInfo: { score: number; breakdown: any }): Promise<{
    summary: string;
    risks: string[];
    strengths: string[];
  }> {
    this.logger.log('Mock AI generating RCS explanation');
    const { score, breakdown } = releaseInfo;

    const risks: string[] = [];
    const strengths: string[] = [];

    // Generate contextual feedback based on breakdown
    if (breakdown.rp < 50) {
      risks.push(
        'Many requirements are not in READY state - consider completing requirement reviews',
      );
    } else if (breakdown.rp >= 80) {
      strengths.push(
        'Requirements planning is solid with most items in READY state',
      );
    }

    if (breakdown.qt < 70) {
      risks.push(
        'Test pass rate is below target - investigate failing tests before release',
      );
    } else if (breakdown.qt >= 90) {
      strengths.push('Excellent test coverage with high pass rate');
    }

    if (breakdown.b < 70) {
      risks.push(
        'Open bugs are impacting release confidence - prioritize critical defect resolution',
      );
    } else if (breakdown.b >= 90) {
      strengths.push('Bug backlog is well managed with minimal open defects');
    }

    if (breakdown.so < 80) {
      risks.push('Security and operations metrics need attention');
    } else {
      strengths.push('Security and operations baseline is healthy');
    }

    let summary: string;
    if (score >= 80) {
      summary = `This release scores ${score}/100, indicating high confidence for deployment. The quality metrics are within acceptable thresholds and the team has addressed major concerns.`;
    } else if (score >= 50) {
      summary = `This release scores ${score}/100, suggesting moderate confidence. There are areas requiring attention before proceeding with deployment.`;
    } else {
      summary = `This release scores ${score}/100, indicating significant concerns. It is recommended to address the identified risks before considering deployment.`;
    }

    return { summary, risks, strengths };
  }
}
